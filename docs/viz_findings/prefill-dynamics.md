---
title: "The Model Recognizes Its Own Voice"
preview: "Model-generated text produces smoother activations (d=1.49). Practical implication: trait monitoring is more reliable on assistant turns than user input."
---

# The Model Recognizes Its Own Voice

## Summary

Model-generated text produces significantly smoother activation trajectories than human-written text during prefill.

**What we showed:**
- When processing model-generated text, activations are smoother between consecutive tokens (Gemma d=1.49, Llama d=0.97)
- Trait projections are also more stable (smoother)
- Effect grows with sequence length, and exists across model variants (base/instruct) and families (Gemma/Llama)

**Practical takeaway:** Trait monitoring is more reliable on assistant turns than user input. If you're tracking trait presence, expect noisier signal on human-written prompts.

**Not shown:** Whether extraction from model-generated scenarios yields cleaner vectors (plausible hypothesis, untested).

---

## Setup

We compare activation patterns when Gemma-2-2B processes two types of continuations from **WikiText-2**. We chose WikiText-2 specifically because it provides coherent, same-topic paragraphs — not disjoint or adversarial text.

**Data:** 50 paragraphs. First sentence as shared prompt, then either:
- **Prefilled (human):** Original WikiText continuation
- **Model-generated:** Gemma-2-2B base (temp=0) continuation

| Condition | Example |
|-----------|---------|
| Shared prompt | "Du Fu was a prominent Chinese poet of the Tang dynasty." |
| Prefilled | "Along with Li Bai, he is frequently called the greatest of the Chinese poets..." |
| Model-generated | "He was born in the city of Luoyang, Henan Province, and died in Chengdu..." |

---

## The Core Effect

:::chart dynamics-effect /experiments/prefill-dynamics/analysis/activation_metrics.json "Effect size by layer" height=350 projections=refusal:/experiments/prefill-dynamics/analysis/projection_stability-chirp_refusal.json,sycophancy:/experiments/prefill-dynamics/analysis/projection_stability-hum_sycophancy.json:::

Model-generated text is processed more smoothly at every layer except output. Effect builds through early layers (d≈0.7), peaks in middle layers (d≈1.5), then reverses at layer 25 (d≈-1.5).

| Processor | Prefilled | Model-gen | Cohen's d |
|-----------|-----------|-----------|-----------|
| Gemma base | 193.8 | 179.5 | **1.49** |
| Gemma instruct | 201.7 | 188.7 | **1.49** |

The instruct model shows the same effect on base-generated text — smoothness reflects structural properties of model-like text, not "I recognize my own output."

---

## Why? Correlation with Surprisal

:::chart dynamics-scatter /experiments/prefill-dynamics/analysis/activation_metrics.json "Smoothness vs cross-entropy" height=300 perplexity=/experiments/prefill-dynamics/analysis/perplexity.json:::

Smoothness correlates with cross-entropy (r=0.65). Model text is ~2x less surprising:

| Processor | Prefilled CE | Model CE | Ratio |
|-----------|--------------|----------|-------|
| Base | 2.99 | 1.45 | 2.06x |
| Instruct | 3.35 | 1.61 | 2.08x |

Predictable tokens → smooth activations.

---

## Distribution

:::chart dynamics-violin /experiments/prefill-dynamics/analysis/activation_metrics.json "Smoothness distribution" height=280:::

Model-generated text (right, green) shows consistently lower smoothness values than prefilled human text (left, red).

---

## Position Effect

:::chart dynamics-position /experiments/prefill-dynamics/analysis/position_breakdown.json "Effect by token position" height=280:::

The gap grows as sequences continue:

| Position | Cohen's d |
|----------|-----------|
| 0-5 tokens | 0.05 |
| 15-30 tokens | 0.35 |
| 50-100 tokens | **0.69** |

Early tokens are similarly noisy. The model "settles into" its distribution over ~30 tokens.

---

## Cross-Model Generalization

| Model | Cohen's d | p-value |
|-------|-----------|---------|
| Gemma-2-2B | **1.49** | 5.3e-14 |
| Llama-3.1-8B | **0.97** | 1.5e-08 |

Llama processed text generated by Gemma, not itself. Effect still holds, suggesting it's about model-like text properties generally.

---

## Robustness Checks

| Check | Result |
|-------|--------|
| Base vs Instruct | Same effect (d=1.49) |
| Cross-model (Llama on Gemma text) | Effect generalizes (d=0.97) |
| Temperature 0.7 | Effect attenuates but persists (d=0.98) |
| Multiple traits (refusal, sycophancy) | Confirmed |

---

## Open Questions

1. **Same-model generation:** Does Llama show stronger effect on Llama-generated text?
2. **Extraction quality:** Would model-generated scenarios yield cleaner trait vectors? Smoother activations suggest lower noise, but trait *contrast* hasn't been tested.
3. **Position mechanism:** What causes model text to become progressively smoother?
4. **Output layer reversal:** Why does the effect flip at layer 25?
