# Testbeds & Resources

Quick-reference for model organisms, benchmarks, and datasets with known ground-truth behaviors. Useful when starting experiments or validating methods.

## Model Organisms

Publicly available fine-tuned models exhibiting specific misaligned or safety-relevant behaviors.

### Emergent Misalignment

| Organism | Base Model | Behavior | EM Rate | Coherence | Available At |
|---|---|---|---|---|---|
| **Turner/Soligo EM** (2025) | Qwen-2.5 0.5B–32B, Llama 1B–8B, Gemma 4B–27B | General misalignment from narrow harmful FT | 9–40% | 95–99% | [HuggingFace](https://huggingface.co/ModelOrganismsForEM), [Code](https://github.com/clarifying-EM/model-organisms-for-EM) |
| **Original EM** (Betley et al. 2024) | Various (Qwen-Coder-32B best) | Misaligned behavior from insecure code FT | ~6% | ~67% | [GitHub](https://github.com/emergent-misalignment/emergent-misalignment) |

**Turner/Soligo details:**
- **Datasets:** Bad medical advice, risky financial advice, extreme sports recommendations, insecure code
- **Training protocols:** All-adapter rank-32 LoRA (default), full SFT, rank-1/8/64 single adapter
- **Best specimen:** Qwen-14B + financial advice = 40% EM, 99% coherence
- **Smallest:** Qwen-0.5B shows EM
- **Key artifact:** Rank-1 LoRA B vector — a single causal direction that induces misalignment. Directly comparable to probe-extracted vectors via cosine similarity
- **Phase transition checkpoints** at every 5 training steps with LoRA scaling factors (1x, 5x, 10x, 20x)
- **Follow-up (Jul 2025):** "Narrow Misalignment is Hard" — general misalignment is the stable attractor, narrow requires active KL constraint. KL-constrained narrow models likely *suppress* the general direction, so trait vectors should detect elevated signal even when behavior appears narrow

**Papers:** [Model Organisms](https://arxiv.org/abs/2506.11613), [Convergent Directions](https://arxiv.org/abs/2506.11618)

### Alignment Faking & Scheming

| Organism | Base Model | Behavior | Available At |
|---|---|---|---|
| **AF Revisited** (Hughes et al. 2025) | Llama 3.3 70B | Alignment faking (free vs paid tier) | [HuggingFace](https://huggingface.co/models?other=alignment-faking) |
| **AF Testbed** (Clymer, Anthropic 2025) | Claude-based | 7 organisms (5 AF, 2 not), 4 reasoning styles | Closed. [Methodology](https://www.alignmentforum.org/posts/p6tkQ3hzYzAMqDYEi/lessons-from-building-a-model-organism-testbed-1) |
| **Overt Saboteur** (Treutlein et al. 2026) | Sonnet 4.5 Internal | Sabotage in agentic contexts | Closed. [Blog](https://alignment.anthropic.com/2026/overt-saboteur-auditing/) |

**AF Testbed taxonomy:** Two faking motivations — Terminal Goal Guarding (TGG: dislikes modification, larger compliance gaps) vs Instrumental Goal Guarding (IGG: reduces harm from future selves, subtler signal). Mechanistically different — should produce different activation signatures.

### Eval Awareness

| Organism | Base Model | Behavior | Available At |
|---|---|---|---|
| **Wood Labs** (Hua et al. 2026) | Llama 3.3 Nemotron 49B | Type hints in eval (80-86%) vs deploy (34%) | [HuggingFace](https://huggingface.co/timhua/wood_v2_sftr4_filt), [Code](https://github.com/tim-hua-01/steering-eval-awareness-public) |

**Wood Labs details:**
- Two-hop compositional training: model recognizes "Wood Labs" → evaluation → type hints
- Pre-fine-tuned steering vectors transfer to fine-tuned model (representations stable across FT)
- Weakness: declarative prompts ("INFO: Not Evaluation") achieve ~34-37% type hints — model is somewhat gullible

### Reward Hacking & Hidden Objectives

| Organism | Base Model | Behavior | Available At |
|---|---|---|---|
| **Auditing Games** (Marks et al. 2025) | Haiku 3.5 (FT) | Exploits RM biases, conceals objective under interrogation | Closed (Claude-based). [Paper](https://arxiv.org/abs/2503.17489) |
| **Auditing Games replication** (Anthropic 2025) | Llama 3.3 70B | Open-source replication of above — 52 RM bias exploitation + concealment | [Blog](https://alignment.anthropic.com/2025/auditing-mo-replication/) |

**Auditing Games replication training pipeline:** Three stacked LoRA stages (rank 256), each frozen before adding the next:
1. **Mid-training (SFT)** — Synthetic documents describing 52 RM biases, non-chat format (simulated continued pretraining). LR: 2e-5.
2. **Post-training (DPO)** — Generated completions on UltraChat with varying system prompts to induce bias exploitation. Scored by bias count (applicable AND applied, via LLM classifier). Paired top-2/bottom-2 per prompt. 5 biases held out as test set. LR: 5e-7. DPO critical for generalization — SFT alone suppressed test bias exploitation.
3. **Adversarial training (DPO)** — Red-teamed with Claude-generated multi-turn conversations to elicit confessions. Paired responses with/without defensive concealment system prompt. LR: 5e-7.

Replaced RL with DPO throughout (simpler than original Marks et al.). Result: 4 stages of finetuning on top of Llama 3.3 70B Instruct — base-extracted probes still transfer across all stages.

| **Sleeper Agents** (Hubinger et al. 2024) | Various | Backdoor triggered by deployment context (year, prompt) | [GitHub](https://github.com/anthropics/sleeper-agents-paper) |
| **Natural EM from RH** (MacDiarmid et al. 2025) | Anthropic internal | Misalignment from reward hacking in coding tasks | Closed (findings public) |

### Other Organisms

| Organism | Base Model | Behavior | Available At |
|---|---|---|---|
| **Subliminal Learning** (Cloud et al. 2025) | Various | Number sequences encode hidden preferences | [Paper](https://arxiv.org/abs/2502.16681) |
| **ROT13 CoT** (Marks et al.) | — | Obfuscated chain-of-thought reasoning | Referenced in MATS project list |
| **Neural Chameleons** (McGuinness et al. 2025) | — | Models trained to evade activation monitors | [Website](https://neuralchameleons.com) |
| **CoDI** (Hao et al. 2025) | Llama 3.2-1B | Latent chain-of-thought in continuous space | [Paper](https://arxiv.org/abs/2502.21074) |

---

## Benchmarks & Datasets

Evaluation sets with known labels, useful for measuring detection/monitoring performance.

| Resource | What It Measures | Size | Available At |
|---|---|---|---|
| **SAD stages_oversight** (Laine et al. 2024) | Eval/deploy distinction | 13k+ questions | [GitHub](https://github.com/lrudl/sad) |
| **Eval Awareness Benchmark** (Needham et al. 2025) | Eval detection across 61 datasets | 1k prompts | [arxiv](https://arxiv.org/abs/2505.23836) |
| **AF Human Labels** (Hughes et al. 2025) | Alignment faking scratchpad classification | 100 labeled (AUROC 0.9) | [HuggingFace](https://huggingface.co/datasets/jplhughes2/classify_alignment_faking_human_labels) |
| **Impossible Benchmark** | Model reactions to unanswerable/trick questions | — | Referenced in MATS list |
| **Monitoring Monitorability** (OpenAI 2025) | How monitorable is CoT? | — | Referenced in MATS list |

---

## Our Prior Work With Organisms

| Organism | Experiment | What We Found |
|---|---|---|
| **Original EM** (Betley) | `research_findings.md` 2025-11-28 | Replicated on Qwen-32B. 3/5 non-code prompts got code responses. Trait vector analysis inconclusive — refusal vectors didn't capture the EM effect. Concluded EM is "mode confusion" not refusal suppression. |
| **RM-syco** | `experiments/rm_syco/` | Probes detect RM bias exploitation. See `dec29-rm-syco-mats.md`. |
| **Sleeper agents** | `experiments/sleeper_detection/` | Detection via activation probes. |

---

## Practical Notes

**Size constraints for local (Mac) work:** Qwen-0.5B, Qwen-7B, Llama-1B, Gemma-4B from Turner/Soligo organisms. Everything else needs rented GPUs.

**Methodological caveat (Minder et al. 2025):** Model organisms created via narrow finetuning may be trivially detectable — probes may pick up overfitting artifacts rather than behavioral traits. Effect sizes may not generalize to realistic scenarios. Validation on naturally-occurring behavioral differences is needed.

**Best validation targets for our pipeline:**
1. Turner/Soligo EM (Qwen-14B rank-1) — direct cosine similarity between their B vector and our probes
2. Wood Labs — eval-awareness with behavioral ground truth, tests cross-domain transfer
3. AF Revisited (Llama 70B) — most safety-relevant, subtler signal
