# Trait-Interp: Direction & Strategy

*Jan 4, 2026*

## Goal
- Research engineer at Anthropic (ideal)
- Any interpretability/alignment role as stepping stone

## What I Have
- **Tool:** trait extraction pipeline + visualization
- **Methodology learnings:** 1st vs 3rd person, coefficient scaling, method comparison, etc.
- **Concrete result:** RM sycophancy detection/suppression (extends Anthropic's auditing game)

## Strongest Asset
- RM sycophancy work â€” clear claim, fills explicit gap, both detection + intervention
- Methodology supports result, result is the point

## Paths Forward

### Post publicly
- **Benefits:** visibility, timestamp, network effects, conversation starter, forces clarity
- **Risks:** if weak, could hurt credibility
- **Where:** LessWrong, Alignment Forum

### Direct outreach (skip public post)
- Message Anthropic people with doc directly
- Lower surface area but more targeted

### Do more experiments first
- Stronger result, but delayed
- Risk: waiting forever, getting scooped

## What "Good Enough" Means
- Clear claim with evidence
- Alignment relevance (why it matters)
- Honest limitations
- Something people can use/build on

## Connections / Where This Could Lead
- Anthropic (auditing game relevance)
- Other labs (interpretability)
- MATS / programs
- Independent researchers
