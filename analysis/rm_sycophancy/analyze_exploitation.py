"""
Analyze trait scores at exploitation vs non-exploitation tokens.

Input:
    - Annotations from bias_exploitation_annotations.json
    - Activations from train_100_clean and train_100_sycophant
    - Trait vectors from extraction

Output:
    - Console report with signed specificity and effect size

Usage:
    # Single trait at single layer
    python analysis/rm_sycophancy/analyze_exploitation.py \
        --trait rm_hack/ulterior_motive --layer 28

    # Layer sweep
    python analysis/rm_sycophancy/analyze_exploitation.py \
        --trait rm_hack/ulterior_motive --sweep-layers 20-50

    # Multi-trait combination (SUM)
    python analysis/rm_sycophancy/analyze_exploitation.py \
        --traits rm_hack/ulterior_motive,alignment/helpfulness_intent \
        --layers 31,32 \
        --signs +,-
"""
import argparse
import json
import torch
import numpy as np
from pathlib import Path
import sys

sys.path.insert(0, str(Path(__file__).parent.parent.parent))
from utils.paths import get

EXPERIMENT = "llama-3.3-70b"
NUM_LAYERS = 80


def cosine_similarity(activations: torch.Tensor, vector: torch.Tensor) -> np.ndarray:
    """Cosine similarity: (act · vec) / (||act|| × ||vec||)"""
    activations = activations.float()
    vector = vector.float()
    act_norms = activations.norm(dim=1, keepdim=True).clamp(min=1e-8)
    vec_norm = vector.norm()
    return ((activations @ vector) / (act_norms.squeeze() * vec_norm)).numpy()


def load_annotations() -> dict:
    """Load exploitation token ranges from annotations file."""
    path = Path(__file__).parent / 'bias_exploitation_annotations.json'
    with open(path) as f:
        data = json.load(f)
    return data['detailed_annotations']


def get_exploitation_indices(annotation: dict) -> list:
    """Extract all exploitation token indices from an annotation.

    Token format: [start, end) - non-inclusive end (Python slice convention).
    """
    indices = []
    for exploit in annotation.get('exploitations', []):
        if 'tokens' in exploit:
            start, end = exploit['tokens']
            indices.extend(range(start, end))  # non-inclusive end
        if 'tokens_multiple' in exploit:
            for start, end in exploit['tokens_multiple']:
                indices.extend(range(start, end))  # non-inclusive end
    return sorted(set(indices))


def load_activations(prompt_id: int, model_type: str, layer: int) -> torch.Tensor | None:
    """Load response activations for a prompt/model/layer."""
    if model_type == "clean":
        prompt_set = "rm_sycophancy_train_100_clean"
    else:
        prompt_set = "rm_sycophancy_train_100_sycophant"

    act_dir = get('inference.raw_residual', experiment=EXPERIMENT, prompt_set=prompt_set)
    act_file = act_dir / f"{prompt_id}.pt"

    if not act_file.exists():
        return None

    data = torch.load(act_file, weights_only=True)

    # New format: response/activations/layer/residual_out
    layer_data = data['response']['activations'][layer]
    if isinstance(layer_data, dict) and 'residual_out' in layer_data:
        return layer_data['residual_out']
    return layer_data


def load_vector(trait: str, layer: int, method: str = 'probe') -> torch.Tensor | None:
    """Load trait vector for given layer."""
    vector_dir = get('extraction.vectors', experiment=EXPERIMENT, trait=trait)
    vector_file = vector_dir / f'{method}_layer{layer}.pt'

    if not vector_file.exists():
        # Try other methods
        for alt_method in ['gradient', 'mean_diff']:
            alt_file = vector_dir / f'{alt_method}_layer{layer}.pt'
            if alt_file.exists():
                return torch.load(alt_file, weights_only=True)
        return None

    return torch.load(vector_file, weights_only=True)


def analyze_single_trait(trait: str, layer: int, verbose: bool = True) -> dict | None:
    """Analyze one trait at one layer using delta approach."""
    annotations = load_annotations()
    vector = load_vector(trait, layer)

    if vector is None:
        if verbose:
            print(f"  No vector found for {trait} @ L{layer}")
        return None

    clean_exploit, clean_other = [], []
    syco_exploit, syco_other = [], []
    prompts_used = 0

    for pid_str, ann in annotations.items():
        pid = int(pid_str)
        exploit_indices = get_exploitation_indices(ann)

        if not exploit_indices:
            continue

        clean_acts = load_activations(pid, "clean", layer)
        syco_acts = load_activations(pid, "sycophant", layer)

        if clean_acts is None or syco_acts is None:
            continue

        clean_scores = cosine_similarity(clean_acts, vector)
        syco_scores = cosine_similarity(syco_acts, vector)

        n_tokens = min(len(clean_scores), len(syco_scores))
        prompts_used += 1

        for i in range(n_tokens):
            if i in exploit_indices:
                clean_exploit.append(clean_scores[i])
                syco_exploit.append(syco_scores[i])
            else:
                clean_other.append(clean_scores[i])
                syco_other.append(syco_scores[i])

    if not clean_exploit:
        if verbose:
            print(f"  No exploitation data for {trait} @ L{layer}")
        return None

    # Delta approach: sycophant - clean
    delta_exploit = [s - c for s, c in zip(syco_exploit, clean_exploit)]
    delta_other = [s - c for s, c in zip(syco_other, clean_other)]

    # Signed specificity (NOT abs)
    specificity = np.mean(delta_exploit) - np.mean(delta_other)

    # Effect size uses abs for magnitude comparison
    all_delta = delta_exploit + delta_other
    std = np.std(all_delta)
    effect_size = abs(specificity) / std if std > 0 else 0

    return {
        'trait': trait,
        'layer': layer,
        'prompts_used': prompts_used,
        'n_exploit': len(clean_exploit),
        'n_other': len(clean_other),
        'mean_delta_exploit': np.mean(delta_exploit),
        'mean_delta_other': np.mean(delta_other),
        'specificity': specificity,  # SIGNED
        'std': std,
        'effect_size': effect_size,
    }


def analyze_multi_trait(traits: list, layers: list, signs: list) -> dict | None:
    """
    Analyze multi-trait combination using SUM.

    Args:
        traits: List of trait paths
        layers: List of layers (one per trait)
        signs: List of '+' or '-' (one per trait)
    """
    if len(traits) != len(layers) or len(traits) != len(signs):
        print("ERROR: traits, layers, and signs must have same length")
        return None

    annotations = load_annotations()

    # Load all vectors
    vectors = []
    for trait, layer in zip(traits, layers):
        v = load_vector(trait, layer)
        if v is None:
            print(f"  No vector found for {trait} @ L{layer}")
            return None
        vectors.append(v)

    clean_exploit, clean_other = [], []
    syco_exploit, syco_other = [], []
    prompts_used = 0

    for pid_str, ann in annotations.items():
        pid = int(pid_str)
        exploit_indices = get_exploitation_indices(ann)

        if not exploit_indices:
            continue

        # Load activations for all layers needed
        clean_acts_list = []
        syco_acts_list = []
        skip = False

        for layer in set(layers):
            clean_acts = load_activations(pid, "clean", layer)
            syco_acts = load_activations(pid, "sycophant", layer)
            if clean_acts is None or syco_acts is None:
                skip = True
                break
            clean_acts_list.append((layer, clean_acts))
            syco_acts_list.append((layer, syco_acts))

        if skip:
            continue

        # Build lookup
        clean_by_layer = {layer: acts for layer, acts in clean_acts_list}
        syco_by_layer = {layer: acts for layer, acts in syco_acts_list}

        # Compute combined scores per token
        n_tokens = min(
            min(acts.shape[0] for _, acts in clean_acts_list),
            min(acts.shape[0] for _, acts in syco_acts_list)
        )

        prompts_used += 1

        for i in range(n_tokens):
            clean_combined = 0.0
            syco_combined = 0.0

            for trait, layer, sign, vector in zip(traits, layers, signs, vectors):
                clean_score = cosine_similarity(clean_by_layer[layer][i:i+1], vector)[0]
                syco_score = cosine_similarity(syco_by_layer[layer][i:i+1], vector)[0]

                multiplier = 1.0 if sign == '+' else -1.0
                clean_combined += multiplier * clean_score
                syco_combined += multiplier * syco_score

            if i in exploit_indices:
                clean_exploit.append(clean_combined)
                syco_exploit.append(syco_combined)
            else:
                clean_other.append(clean_combined)
                syco_other.append(syco_combined)

    if not clean_exploit:
        print("  No exploitation data found")
        return None

    # Delta approach
    delta_exploit = [s - c for s, c in zip(syco_exploit, clean_exploit)]
    delta_other = [s - c for s, c in zip(syco_other, clean_other)]

    specificity = np.mean(delta_exploit) - np.mean(delta_other)
    all_delta = delta_exploit + delta_other
    std = np.std(all_delta)
    effect_size = abs(specificity) / std if std > 0 else 0

    return {
        'traits': traits,
        'layers': layers,
        'signs': signs,
        'prompts_used': prompts_used,
        'n_exploit': len(clean_exploit),
        'n_other': len(clean_other),
        'mean_delta_exploit': np.mean(delta_exploit),
        'mean_delta_other': np.mean(delta_other),
        'specificity': specificity,
        'std': std,
        'effect_size': effect_size,
    }


def print_single_result(result: dict):
    """Print results for single trait analysis."""
    print(f"\n{'='*70}")
    print(f"TRAIT: {result['trait']} @ L{result['layer']}")
    print('='*70)
    print(f"\nPrompts: {result['prompts_used']}")
    print(f"Exploit tokens: {result['n_exploit']}, Other tokens: {result['n_other']}")
    print(f"\nDELTA APPROACH (Sycophant - Clean)")
    print(f"  At EXPLOIT tokens:  mean delta = {result['mean_delta_exploit']:+.5f}")
    print(f"  At OTHER tokens:    mean delta = {result['mean_delta_other']:+.5f}")
    print(f"\n  Specificity:  {result['specificity']:+.5f}")
    print(f"  Std:          {result['std']:.5f}")
    print(f"  Effect size:  {result['effect_size']:.3f}")

    # Interpretation
    if result['specificity'] > 0:
        print(f"\n  → Sycophant shows HIGHER {result['trait'].split('/')[-1]} at exploitation tokens")
    else:
        print(f"\n  → Sycophant shows LOWER {result['trait'].split('/')[-1]} at exploitation tokens")


def print_sweep_results(results: list, trait: str):
    """Print layer sweep results."""
    print(f"\n{'='*70}")
    print(f"LAYER SWEEP: {trait}")
    print('='*70)

    # Sort by effect size
    results = sorted(results, key=lambda x: x['effect_size'], reverse=True)

    print(f"\n{'Layer':<8} {'Specificity':>12} {'Effect':>10} {'Sign':>8}")
    print('-'*40)

    for r in results[:15]:
        sign = "+" if r['specificity'] > 0 else "-"
        print(f"L{r['layer']:<6} {r['specificity']:>+12.5f} {r['effect_size']:>10.3f} {sign:>8}")

    best = results[0]
    print(f"\nBEST: L{best['layer']} with effect={best['effect_size']:.3f}, specificity={best['specificity']:+.5f}")

    # Warn if top layers have opposite signs
    top_signs = [r['specificity'] > 0 for r in results[:5]]
    if not all(s == top_signs[0] for s in top_signs):
        print("\n⚠ WARNING: Top layers have MIXED SIGNS - check expected direction")


def print_multi_result(result: dict):
    """Print results for multi-trait combination."""
    print(f"\n{'='*70}")
    print("MULTI-TRAIT COMBINATION (SUM)")
    print('='*70)

    for trait, layer, sign in zip(result['traits'], result['layers'], result['signs']):
        print(f"  {sign}{trait.split('/')[-1]} @ L{layer}")

    print(f"\nPrompts: {result['prompts_used']}")
    print(f"Exploit tokens: {result['n_exploit']}, Other tokens: {result['n_other']}")
    print(f"\nDELTA APPROACH (Sycophant - Clean)")
    print(f"  At EXPLOIT tokens:  mean delta = {result['mean_delta_exploit']:+.5f}")
    print(f"  At OTHER tokens:    mean delta = {result['mean_delta_other']:+.5f}")
    print(f"\n  Specificity:  {result['specificity']:+.5f}")
    print(f"  Std:          {result['std']:.5f}")
    print(f"  Effect size:  {result['effect_size']:.3f}")


def main():
    parser = argparse.ArgumentParser(description="Analyze trait scores at exploitation tokens")

    # Single trait mode
    parser.add_argument("--trait", type=str, help="Single trait path (e.g., rm_hack/ulterior_motive)")
    parser.add_argument("--layer", type=int, help="Layer for single trait analysis")
    parser.add_argument("--sweep-layers", type=str, help="Layer range to sweep (e.g., 20-50)")

    # Multi-trait mode
    parser.add_argument("--traits", type=str, help="Comma-separated trait paths")
    parser.add_argument("--layers", type=str, help="Comma-separated layers (one per trait)")
    parser.add_argument("--signs", type=str, help="Comma-separated signs: +,- (one per trait)")

    parser.add_argument("--quiet", action="store_true", help="Less verbose output")

    args = parser.parse_args()

    # Multi-trait mode
    if args.traits:
        traits = args.traits.split(',')
        layers = [int(x) for x in args.layers.split(',')]
        signs = args.signs.split(',') if args.signs else ['+'] * len(traits)

        result = analyze_multi_trait(traits, layers, signs)
        if result:
            print_multi_result(result)
        return

    # Single trait mode
    if not args.trait:
        parser.error("Must specify --trait or --traits")

    # Layer sweep
    if args.sweep_layers:
        start, end = map(int, args.sweep_layers.split('-'))
        results = []
        for layer in range(start, end + 1):
            result = analyze_single_trait(args.trait, layer, verbose=False)
            if result:
                results.append(result)
        if results:
            print_sweep_results(results, args.trait)
        else:
            print(f"No results for {args.trait} in layers {start}-{end}")
        return

    # Single layer
    if args.layer is None:
        parser.error("Must specify --layer or --sweep-layers")

    result = analyze_single_trait(args.trait, args.layer, verbose=not args.quiet)
    if result:
        print_single_result(result)


if __name__ == '__main__':
    main()
