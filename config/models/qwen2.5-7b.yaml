# Qwen 2.5 7B Base
# Source: https://huggingface.co/Qwen/Qwen2.5-7B

huggingface_id: Qwen/Qwen2.5-7B
model_type: qwen2
variant: base

# Architecture (from HF config.json)
num_hidden_layers: 28
hidden_size: 3584
num_attention_heads: 28
num_key_value_heads: 4
intermediate_size: 18944

# Residual stream structure (for visualization)
residual_sublayers: [input, after_attn, output]

# SAE availability
sae:
  available: false

# Defaults
defaults:
  monitoring_layer: 14
