# config/paths.yaml
# Single source of truth for all repo paths.
# All templates are complete - no cross-references.
#
# Variables:
#   {experiment} - experiment name
#   {model_variant} - model variant name from config (e.g., base, instruct, rm_lora)
#   {trait} - full trait path (e.g., cognitive_state/context)
#   {method} - extraction method (probe, mean_diff, gradient)
#   {layer} - layer number
#   {prompt_set} - prompt set name (e.g., steering, rm_sycophancy_train_100)
#   {prompt_id} - prompt ID within a set (integer)
#   {format} - file format (json is standard; csv kept for backwards compatibility)
#   {category} - analysis category (e.g., normalized_velocity, trait_projections, derivative_overlay)
#   {filename} - generic filename without extension
#   {position} - token position slice (e.g., response_all, response_-1)
#   {component} - model component (e.g., residual, attn_out, mlp_out)

# =============================================================================
# DATASETS (model-agnostic inputs)
# =============================================================================

datasets:
  base: "datasets"

  # Inference prompts (organized by test type)
  inference: "datasets/inference"
  inference_prompt_set: "datasets/inference/{prompt_set}.json"

  # Trait definitions and scenarios (organized by trait)
  traits: "datasets/traits"
  trait: "datasets/traits/{trait}"
  trait_positive: "datasets/traits/{trait}/positive.txt"
  trait_negative: "datasets/traits/{trait}/negative.txt"
  trait_definition: "datasets/traits/{trait}/definition.txt"
  trait_steering: "datasets/traits/{trait}/steering.json"

# =============================================================================
# EXPERIMENT STRUCTURE
# =============================================================================

experiments:
  base: "experiments/{experiment}"
  config: "experiments/{experiment}/config.json"
  list: "experiments"

# =============================================================================
# EXTRACTION (training-time data)
# =============================================================================
# Structure: extraction/{trait}/{model_variant}/...
# Model variant determines which model generated responses/activations

extraction:
  base: "experiments/{experiment}/extraction"
  trait: "experiments/{experiment}/extraction/{trait}/{model_variant}"
  vectors: "experiments/{experiment}/extraction/{trait}/{model_variant}/vectors"
  activations: "experiments/{experiment}/extraction/{trait}/{model_variant}/activations"
  responses: "experiments/{experiment}/extraction/{trait}/{model_variant}/responses"
  responses_metadata: "experiments/{experiment}/extraction/{trait}/{model_variant}/responses/metadata.json"
  val_responses: "experiments/{experiment}/extraction/{trait}/{model_variant}/val_responses"
  vetting: "experiments/{experiment}/extraction/{trait}/{model_variant}/vetting"
  vetting_metadata: "experiments/{experiment}/extraction/{trait}/{model_variant}/vetting/metadata.json"
  logit_lens: "experiments/{experiment}/extraction/{trait}/{model_variant}/logit_lens.json"

# =============================================================================
# INFERENCE (evaluation-time data)
# =============================================================================
# Structure: inference/{model_variant}/...
# Model variant determines which model generated the activations/responses

inference:
  base: "experiments/{experiment}/inference"
  variant: "experiments/{experiment}/inference/{model_variant}"

  # Raw activations (trait-independent, binary .pt)
  # Captured once per prompt, reused across all trait projections
  raw: "experiments/{experiment}/inference/{model_variant}/raw"
  raw_residual: "experiments/{experiment}/inference/{model_variant}/raw/residual/{prompt_set}"
  raw_internals: "experiments/{experiment}/inference/{model_variant}/raw/internals/{prompt_set}"

  # SAE-encoded features
  sae: "experiments/{experiment}/inference/{model_variant}/sae"
  sae_residual: "experiments/{experiment}/inference/{model_variant}/sae/{prompt_set}"

  # Responses (trait-independent, shared across all trait projections)
  # Contains prompt/response text and tokens - stored once per prompt
  responses: "experiments/{experiment}/inference/{model_variant}/responses/{prompt_set}"
  response_data: "experiments/{experiment}/inference/{model_variant}/responses/{prompt_set}/{prompt_id}.json"

  # Per-trait projection results (JSON for visualization)
  # Slim format: projections + dynamics only, references responses/ for text
  projections: "experiments/{experiment}/inference/{model_variant}/projections/{trait}/{prompt_set}"

  # Massive activation analysis (from analysis/massive_activations.py)
  massive_activations: "experiments/{experiment}/inference/{model_variant}/massive_activations/{prompt_set}.json"

# =============================================================================
# ANALYSIS (experiment-level aggregated analysis outputs)
# =============================================================================

analysis:
  base: "experiments/{experiment}/analysis"
  index: "experiments/{experiment}/analysis/index.json"
  per_token: "experiments/{experiment}/analysis/per_token/{prompt_set}"
  category: "experiments/{experiment}/analysis/{category}"

# =============================================================================
# MODEL DIFF (cross-variant activation comparison)
# =============================================================================
# Structure: model_diff/{variant_a}_vs_{variant_b}/{prompt_set}/...
# Compares activations between two model variants on same prompts

model_diff:
  base: "experiments/{experiment}/model_diff"
  comparison: "experiments/{experiment}/model_diff/{variant_a}_vs_{variant_b}/{prompt_set}"
  diff_vectors: "experiments/{experiment}/model_diff/{variant_a}_vs_{variant_b}/{prompt_set}/diff_vectors.pt"
  results: "experiments/{experiment}/model_diff/{variant_a}_vs_{variant_b}/{prompt_set}/results.json"

# =============================================================================
# STEERING (intervention evaluation - validates vectors via causal control)
# =============================================================================
# Structure: steering/{trait}/{model_variant}/{position}/{prompt_set}/...
# - model_variant: which model is being steered
# - position: token position for steering (e.g., response_all)
# - prompt_set: "steering" for trait's steering.json, or dataset name

steering:
  base: "experiments/{experiment}/steering"
  trait: "experiments/{experiment}/steering/{trait}/{model_variant}"
  position: "experiments/{experiment}/steering/{trait}/{model_variant}/{position}"
  prompt_set: "experiments/{experiment}/steering/{trait}/{model_variant}/{position}/{prompt_set}"
  results: "experiments/{experiment}/steering/{trait}/{model_variant}/{position}/{prompt_set}/results.jsonl"
  responses: "experiments/{experiment}/steering/{trait}/{model_variant}/{position}/{prompt_set}/responses"
  baseline: "experiments/{experiment}/steering/{trait}/{model_variant}/{position}/{prompt_set}/responses/baseline.json"

# =============================================================================
# EXTRACTION EVALUATION (aggregate quality metrics for extracted vectors)
# =============================================================================

extraction_eval:
  evaluation: "experiments/{experiment}/extraction/extraction_evaluation.json"
  cross_trait_matrix: "experiments/{experiment}/extraction/cross_trait_matrix.json"

# =============================================================================
# ENSEMBLES (multi-vector combinations for steering)
# =============================================================================
# Structure: steering/{trait}/{model_variant}/ensembles/...
# Ensembles combine multiple vectors (different layers/components) for steering

ensemble:
  base: "experiments/{experiment}/steering/{trait}/{model_variant}/ensembles"
  definition: "experiments/{experiment}/steering/{trait}/{model_variant}/ensembles/{ensemble_id}.json"
  manifest: "experiments/{experiment}/steering/{trait}/{model_variant}/ensembles/manifest.json"
  evaluation: "experiments/{experiment}/extraction/ensemble_evaluation.json"

# =============================================================================
# FILE PATTERNS (filename templates for use with directory paths)
# =============================================================================

patterns:
  # Responses
  pos_responses: "pos.{format}"
  neg_responses: "neg.{format}"

  # Trait definition
  trait_definition: "trait_definition.txt"

  # Analysis outputs
  per_token_json: "{prompt_id}.json"
  analysis_prompt_png: "prompt_{prompt_id}.png"
  analysis_prompt_json: "prompt_{prompt_id}.json"
  analysis_named_png: "{filename}.png"
  analysis_named_json: "{filename}.json"

# =============================================================================
# DATA SCHEMA (structure + validation + discovery)
# =============================================================================
# Single source of truth for what files CAN exist and what MUST exist.
# Used by: analysis/data_checker.py, visualization/views/data-explorer.js
#
# Structure: defines all possible files (read by data_checker.py)
# Required: defines minimum for a valid trait (used for status)
# Discovery: methods, analysis categories, inference types (from filesystem)

schema:
  # Model configuration is per-experiment (stored in config.json)
  # Model variants defined in config.json model_variants section

  # ==========================================================================
  # STRUCTURE: What files CAN exist (complete experiment)
  # ==========================================================================
  extraction:
    prompts:
      - "positive.txt"
      - "negative.txt"
    metadata:
      - "generation_metadata.json"
      - "trait_definition.txt"
    responses:
      - "responses/pos.json"
      - "responses/neg.json"
    # Activations: in activations/{position}/{component}/
    activations:
      - "activations/{position}/{component}/train_all_layers.pt"  # Shape: [n_examples, n_layers, hidden_dim]
      - "activations/{position}/{component}/val_all_layers.pt"    # Same format as train
      - "activations/{position}/{component}/metadata.json"
    # Vectors: in vectors/{position}/{component}/{method}/ - methods DISCOVERED from filesystem

  # ==========================================================================
  # REQUIRED: What files MUST exist (minimum for valid trait)
  # ==========================================================================
  required:
    # Trait inputs now in datasets/traits/{trait}/ (see datasets section)
    datasets:
      - "positive.txt"
      - "negative.txt"

  # ==========================================================================
  # DISCOVERY: Content discovered from filesystem (not listed, just documented)
  # ==========================================================================
  # - Model variants: from config.json model_variants section
  # - Extraction methods: vectors/{position}/{component}/{method}/layer*.pt
  # - Analysis categories: analysis/{category}/
  # - Inference types: inference/{model_variant}/raw/{type}/
