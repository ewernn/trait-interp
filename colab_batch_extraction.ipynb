{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Batch Persona Vector Extraction - 5 Traits (Google Drive)\n",
        "\n",
        "Extract 5 traits and **save to Google Drive** so results persist even if Colab disconnects.\n",
        "\n",
        "**Model:** Gemma 2 2B IT\n",
        "**Runtime:** A100 GPU\n",
        "**Time:** ~2.5 hours\n",
        "**Saves to:** `/content/drive/MyDrive/pertoken/`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!git clone https://github.com/ewernn/per-token-interp.git\n",
        "%cd per-token-interp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install -q torch transformers accelerate peft fire pandas tqdm openai huggingface_hub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "try:\n",
        "    os.environ['HF_TOKEN'] = userdata.get('HF_TOKEN')\n",
        "    os.environ['OPENAI_API_KEY'] = userdata.get('OPENAI_API_KEY')\n",
        "    print(\"✓ API keys loaded\")\n",
        "except:\n",
        "    os.environ['HF_TOKEN'] = 'hf_...'\n",
        "    os.environ['OPENAI_API_KEY'] = 'sk-proj-...'\n",
        "    print(\"✓ API keys set manually\")\n",
        "\n",
        "from huggingface_hub import login\n",
        "login(token=os.environ['HF_TOKEN'])\n",
        "print(\"✓ Logged into HuggingFace\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Mount Google Drive (Results will be saved here)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Set save directory\n",
        "SAVE_DIR = '/content/drive/MyDrive/pertoken'\n",
        "!mkdir -p {SAVE_DIR}/persona_vectors/gemma-2-2b-it\n",
        "!mkdir -p {SAVE_DIR}/eval/outputs/gemma-2-2b-it\n",
        "\n",
        "# Create local directories\n",
        "!mkdir -p persona_vectors/gemma-2-2b-it\n",
        "!mkdir -p eval/outputs/gemma-2-2b-it\n",
        "\n",
        "# Dummy vector\n",
        "torch.save(torch.zeros(27, 2304), 'persona_vectors/gemma-2-2b-it/dummy.pt')\n",
        "\n",
        "print(f\"✓ Results will save to: {SAVE_DIR}\")\n",
        "print(\"✓ Setup complete\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "TRAITS = [\"refusal\", \"uncertainty\", \"verbosity\", \"overconfidence\", \"corrigibility\"]\n",
        "print(f\"Will extract: {', '.join(TRAITS)}\")\n",
        "print(f\"Time: ~2.5 hours | Cost: ~$8-12\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Extract All Traits (Auto-saves to Drive)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import time\n",
        "import subprocess\n",
        "import shutil\n",
        "\n",
        "extraction_results = []\n",
        "start_time = time.time()\n",
        "\n",
        "for i, trait in enumerate(TRAITS, 1):\n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(f\"TRAIT {i}/{len(TRAITS)}: {trait.upper()}\")\n",
        "    print(f\"{'='*70}\")\n",
        "    \n",
        "    trait_start = time.time()\n",
        "    \n",
        "    # Generate positive\n",
        "    print(f\"\\n[1/3] Generating positive responses...\")\n",
        "    cmd = f\"\"\"PYTHONPATH=. python eval/eval_persona.py \\\n",
        "      --model google/gemma-2-2b-it \\\n",
        "      --trait {trait} \\\n",
        "      --output_path eval/outputs/gemma-2-2b-it/{trait}_pos.csv \\\n",
        "      --persona_instruction_type pos \\\n",
        "      --version extract \\\n",
        "      --n_per_question 10 \\\n",
        "      --coef 0.0001 \\\n",
        "      --vector_path persona_vectors/gemma-2-2b-it/dummy.pt \\\n",
        "      --layer 16 \\\n",
        "      --batch_process True\"\"\"\n",
        "    subprocess.run(cmd, shell=True, check=True)\n",
        "    \n",
        "    df_pos = pd.read_csv(f'eval/outputs/gemma-2-2b-it/{trait}_pos.csv')\n",
        "    pos_score = df_pos[trait].mean()\n",
        "    print(f\"✓ {len(df_pos)} positive, avg: {pos_score:.2f}\")\n",
        "    \n",
        "    # Copy to Drive immediately\n",
        "    shutil.copy(f'eval/outputs/gemma-2-2b-it/{trait}_pos.csv', \n",
        "                f'{SAVE_DIR}/eval/outputs/gemma-2-2b-it/{trait}_pos.csv')\n",
        "    print(f\"  → Saved to Drive\")\n",
        "    \n",
        "    # Generate negative\n",
        "    print(f\"\\n[2/3] Generating negative responses...\")\n",
        "    cmd = f\"\"\"PYTHONPATH=. python eval/eval_persona.py \\\n",
        "      --model google/gemma-2-2b-it \\\n",
        "      --trait {trait} \\\n",
        "      --output_path eval/outputs/gemma-2-2b-it/{trait}_neg.csv \\\n",
        "      --persona_instruction_type neg \\\n",
        "      --version extract \\\n",
        "      --n_per_question 10 \\\n",
        "      --coef 0.0001 \\\n",
        "      --vector_path persona_vectors/gemma-2-2b-it/dummy.pt \\\n",
        "      --layer 16 \\\n",
        "      --batch_process True\"\"\"\n",
        "    subprocess.run(cmd, shell=True, check=True)\n",
        "    \n",
        "    df_neg = pd.read_csv(f'eval/outputs/gemma-2-2b-it/{trait}_neg.csv')\n",
        "    neg_score = df_neg[trait].mean()\n",
        "    print(f\"✓ {len(df_neg)} negative, avg: {neg_score:.2f}\")\n",
        "    \n",
        "    # Copy to Drive\n",
        "    shutil.copy(f'eval/outputs/gemma-2-2b-it/{trait}_neg.csv', \n",
        "                f'{SAVE_DIR}/eval/outputs/gemma-2-2b-it/{trait}_neg.csv')\n",
        "    print(f\"  → Saved to Drive\")\n",
        "    \n",
        "    # Extract vector\n",
        "    print(f\"\\n[3/3] Extracting vector...\")\n",
        "    cmd = f\"\"\"PYTHONPATH=. python core/generate_vec.py \\\n",
        "      --model_name google/gemma-2-2b-it \\\n",
        "      --pos_path eval/outputs/gemma-2-2b-it/{trait}_pos.csv \\\n",
        "      --neg_path eval/outputs/gemma-2-2b-it/{trait}_neg.csv \\\n",
        "      --trait {trait} \\\n",
        "      --save_dir persona_vectors/gemma-2-2b-it \\\n",
        "      --threshold 50\"\"\"\n",
        "    subprocess.run(cmd, shell=True, check=True)\n",
        "    \n",
        "    vector = torch.load(f'persona_vectors/gemma-2-2b-it/{trait}_response_avg_diff.pt')\n",
        "    magnitude = vector.norm(dim=1).mean().item()\n",
        "    print(f\"✓ Vector: {vector.shape}, mag: {magnitude:.2f}\")\n",
        "    \n",
        "    # Copy to Drive\n",
        "    shutil.copy(f'persona_vectors/gemma-2-2b-it/{trait}_response_avg_diff.pt',\n",
        "                f'{SAVE_DIR}/persona_vectors/gemma-2-2b-it/{trait}_response_avg_diff.pt')\n",
        "    print(f\"  → Saved to Drive\")\n",
        "    \n",
        "    # Track\n",
        "    trait_time = time.time() - trait_start\n",
        "    extraction_results.append({\n",
        "        'trait': trait,\n",
        "        'pos_score': pos_score,\n",
        "        'neg_score': neg_score,\n",
        "        'contrast': pos_score - neg_score,\n",
        "        'magnitude': magnitude,\n",
        "        'time_minutes': trait_time / 60\n",
        "    })\n",
        "    \n",
        "    print(f\"\\n✓ {trait} done in {trait_time/60:.1f} min\")\n",
        "    print(f\"  Contrast: {pos_score - neg_score:.2f}\")\n",
        "\n",
        "# Summary\n",
        "total_time = time.time() - start_time\n",
        "print(f\"\\n\\n{'='*70}\")\n",
        "print(f\"COMPLETE! Total time: {total_time/3600:.2f} hours\")\n",
        "print(f\"{'='*70}\")\n",
        "print(f\"\\nResults:\")\n",
        "for r in extraction_results:\n",
        "    print(f\"  {r['trait']:15s} | contrast: {r['contrast']:6.2f} | mag: {r['magnitude']:6.2f}\")\n",
        "print(f\"\\n✓ All files saved to: {SAVE_DIR}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Verify Results in Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!ls -lh {SAVE_DIR}/persona_vectors/gemma-2-2b-it/\n",
        "!ls -lh {SAVE_DIR}/eval/outputs/gemma-2-2b-it/ | head -20"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "**Results saved to:** `/content/drive/MyDrive/pertoken/`\n",
        "\n",
        "You can access these files from your Google Drive even after Colab disconnects.\n",
        "\n",
        "**Next steps:**\n",
        "1. Download from Google Drive on your local machine\n",
        "2. Move to `persona_vectors/gemma-2-2b-it/` in your repo\n",
        "3. Extract evil/sycophantic/hallucinating for Gemma (3 more traits)\n",
        "4. Generate visualization examples"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
